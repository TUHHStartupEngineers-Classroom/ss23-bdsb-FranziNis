[
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "I had major problems with the data.table-package and could not complete this challenge. I think I would be able to do it if I still had more time to understand it."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Challenge 1\nUnfortunately I was not able to print the y-axis-label in English. I also was not able to use geom_label() because I could not figure out how to only label the United States and on the end position. When I set it to a specific position the legend was referring to the text and not the line anymore…\n\nlibrary(tidyverse)\nlibrary(RColorBrewer)\nlibrary(lubridate)\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 313070 Columns: 67\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# I'll need the following: continent, location, date, total cases\n\n# Data Manipulation\n\ncovid_time_tbl <- covid_data_tbl %>%\n  select(location, continent, date, total_cases) %>%\n  filter(location %in% c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")) %>%\n  mutate(final_cases = max(total_cases, na.rm = TRUE)) %>% \n  mutate(across(total_cases, ~replace_na(., 0))) \n\n\n# Data Visualization\n\ncovid_time_tbl %>%\n  \n  ggplot(aes(date, total_cases, color = location))+\n  \n  geom_line(linewidth = 1)+\n  #geom_label(aes(x = as.Date(\"2023-05-24\"), y = 103436829, \n  #       label = \"103.436.829\"), show.legend = TRUE)+\n  annotate(geom=\"text\", x=as.Date(\"2023-05-24\"), y= 107000000, \n           label=\"103.436.829\") +\n  \n  # Formatting\n  labs(\n    title = \"COVID-19 confirmed cases\",\n    subtitle = \"as of 24/05/2023\",\n    y = \"Cumulative Cases\",\n    x = \"\"\n  )+\n  scale_y_continuous(breaks = seq(0, 120000000, by = 20000000), minor_breaks = seq(0, 120000000, by = 10000000),\n                     labels = scales::label_number(scale = 1e-6, \n                                                    prefix = \"\",\n                                                    suffix =\" M\"))+\n  scale_x_date(date_breaks = \"2 months\", date_labels = (date_format = \"%B '%y\"))+\n  scale_color_brewer(\"Countries\", palette = \"Dark2\")+\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(),\n    axis.title.y = element_text(face = \"bold\"),\n    axis.title.x = element_blank(),\n    legend.position = \"bottom\",\n    panel.grid = element_line(color = \"grey\"),\n    panel.background = element_blank()\n  )\n\n\n\n\n\n\n\n\n2 Challenge 2\nThis is the best I could do with the time I had. I could not render it and did not have the time to figure out why… It says it cannot use x = long, y = lat, so I took out and now there is no visual map. It actually is a map and looks really familiar to the one you uploaded… So I will just give you this.\n\nlibrary(maps)\nlibrary(tidyverse)\nlibrary(RColorBrewer)\nlibrary(lubridate)\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 313070 Columns: 67\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nworld <- map_data(\"world\") %>%\n  select(region)\n\nworld_map <- map_data(\"world\")\n\ncovid_world_tbl <- covid_data_tbl %>%\n  select(location, new_deaths, population) %>%\n  mutate(across(new_deaths, ~replace_na(., 0))) %>%\n  group_by(location, population) %>%\n  summarise(deaths = sum(new_deaths)) %>%\n  ungroup() %>%\n  mutate(mortality = deaths / population) %>%\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %>%\n  distinct() %>%\n  right_join(world, by = c(\"location\" = \"region\"))\n\n#> `summarise()` has grouped output by 'location'. You can override using the\n#> `.groups` argument.\n\nsum(covid_world_tbl$deaths, na.rm = TRUE)\n\n#> [1] 15446765024\n\n# Data Visualization\n\ncovid_world_tbl %>%\n  \n  ggplot(aes( fill = mortality)) +\n  geom_map(aes( map_id = location), map = world_map) + \n  \n  # formatting\n  labs(\n    title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n    subtitle = \"Around 15.4 Million confirmed COVID-19 deaths worldwide\",\n    y = \"\",\n    x = \"\"\n  )+\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nMy Challenge is all the way down\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Tidyverse",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Challenge 2.1\nFor the first challenge I looked up the weather in Moliets-et-Maa since this is one of my vacation destinations for this summer.\n\n# 1.0 LIBRARIES ----\n\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(rvest)     # HTML Hacking & Web Scraping\nlibrary(xopen)     # Quickly opening URLs\nlibrary(jsonlite)  # converts JSON files to R objects\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(lubridate)\n\n# Moliets' weather forecast for the next 16 days (21.05.2023) ----\nweather_moliets          <- \"https://www.wetter.com/wetter_aktuell/wettervorhersage/16_tagesvorhersage/frankreich/moliets-et-maa/FR2993520.html\"\nhtml_weather    <- weather_moliets %>%\n  read_html()\n\n# The first week had another node than the last days, so I had to extract them two different ways and eventually add them back together\ndate_8to16 <- html_weather %>%\n  html_nodes(\".no-hover .date\")%>%\n  html_text() %>%\n  stringr::str_extract(\"\\\\w+[:space:]\\\\d+\\\\.\\\\d+\\\\.\") \ndate_8to16\n\n#> [1] \"MO 29.05.\" \"DI 30.05.\" \"MI 31.05.\" \"DO 01.06.\" \"FR 02.06.\" \"SA 03.06.\"\n#> [7] \"SO 04.06.\" \"MO 05.06.\" \"DI 06.06.\"\n\ndate_merged <- html_weather %>%\n  html_nodes(\".bg--blue-gradient .date\") %>% # these are only the first 7 days\n  html_text() %>%\n  c(date_8to16) # so I added the last 11 days\ndate_merged \n\n#>  [1] \"MO 22.05.\" \"DI 23.05.\" \"MI 24.05.\" \"DO 25.05.\" \"FR 26.05.\" \"SA 27.05.\"\n#>  [7] \"SO 28.05.\" \"MO 29.05.\" \"DI 30.05.\" \"MI 31.05.\" \"DO 01.06.\" \"FR 02.06.\"\n#> [13] \"SA 03.06.\" \"SO 04.06.\" \"MO 05.06.\" \"DI 06.06.\"\n\nweekday <- date_merged %>%\n  stringr::str_extract(\"\\\\w+\") # removes the date\nweekday\n\n#>  [1] \"MO\" \"DI\" \"MI\" \"DO\" \"FR\" \"SA\" \"SO\" \"MO\" \"DI\" \"MI\" \"DO\" \"FR\" \"SA\" \"SO\" \"MO\"\n#> [16] \"DI\"\n\n# the dates of the weather forecast did not come with the year\n# Create a year vector, so I can add it to the date (dd.mm.) to turn it into the date format\nyear <- c(\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\n          \"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\n          \"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\") # I didn't know how to make it pretty\n\ndate <- date_merged %>%\n  stringr::str_extract(\"\\\\d+\\\\.\\\\d+\\\\.\") %>%  # extracting the weekday\n  paste(year) %>%\n  stringr::str_remove(\"[:space:]\") %>% # removing the space\n  dmy() # That is the final date\ndate\n\n#>  [1] \"2023-05-22\" \"2023-05-23\" \"2023-05-24\" \"2023-05-25\" \"2023-05-26\"\n#>  [6] \"2023-05-27\" \"2023-05-28\" \"2023-05-29\" \"2023-05-30\" \"2023-05-31\"\n#> [11] \"2023-06-01\" \"2023-06-02\" \"2023-06-03\" \"2023-06-04\" \"2023-06-05\"\n#> [16] \"2023-06-06\"\n\nmax_temp <- html_weather %>%\n  html_nodes(\".temp-max\") %>%\n  html_text()\nmax_temp\n\n#>  [1] \"19°\" \"19°\" \"19°\" \"21°\" \"25°\" \"17°\" \"16°\" \"17°\" \"21°\" \"21°\" \"22°\" \"25°\"\n#> [13] \"23°\" \"20°\" \"19°\" \"20°\"\n\nmin_temp <- html_weather %>%\n  html_nodes(\".temp-min\") %>%\n  html_text() %>%\n  stringr::str_extract(\"\\\\d+°\") # removes the space and \"/\"\nmin_temp\n\n#>  [1] \"15°\" \"15°\" \"15°\" \"15°\" \"15°\" \"12°\" \"13°\" \"15°\" \"12°\" \"14°\" \"16°\" \"16°\"\n#> [13] \"16°\" \"17°\" \"17°\" \"17°\"\n\nweather_state <- html_weather %>%\n  html_nodes(\".weather-state\") %>%\n  html_text() %>%\n  stringr::str_extract(\"\\\\w+[:space:]\\\\w+|\\\\w+\") # wasn't pretty w/o the extraction\nweather_state\n\n#>  [1] \"wolkig\"         \"wolkig\"         \"wolkig\"         \"leicht bewölkt\"\n#>  [5] \"leicht bewölkt\" \"sonnig\"         \"sonnig\"         \"leicht bewölkt\"\n#>  [9] \"sonnig\"         \"sonnig\"         \"sonnig\"         \"leicht bewölkt\"\n#> [13] \"leicht bewölkt\" \"Regen\"          \"wolkig\"         \"wolkig\"\n\n# The final tibble\nWeather_tbl_joined <- tibble(date, weekday, max_temp, min_temp, weather_state)\nWeather_tbl_joined"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "Hello,\nThis journal won’t be my best work since I did not give myself enough time to work on it. I underestimated it. But I truly tried. Even though I might not have finished all challenges. Next time I should take more of my time and work on this with more space and time to think about it."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/01_tidyverse - Kopie.html",
    "href": "content/01_journal/01_tidyverse - Kopie.html",
    "title": "Tidyverse - Challenge 1",
    "section": "",
    "text": "1 I am hoping this works out.\nThe following should be a code. It does not with the code"
  },
  {
    "objectID": "content/01_journal/05_tidyverse - Kopie.html",
    "href": "content/01_journal/05_tidyverse - Kopie.html",
    "title": "Tidyverse - Challenge 1",
    "section": "",
    "text": "1 I am hoping this works out.\nThe following should be a code. It does not with the code"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#revenue-by-state",
    "href": "content/01_journal/01_tidyverse.html#revenue-by-state",
    "title": "Tidyverse",
    "section": "\n7.1 Revenue by state",
    "text": "7.1 Revenue by state\n\n# CHALLENGE 1 Preparation ----\n# 1.0 Load libraries ----\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n# 2.0 Importing Files ----\nbikes_tbl <- read_excel(path = \"../../ds_data/01_bike_sales/01_raw_data/bikes.xlsx\")\norderlines_tbl <- read_excel(path = \"../../ds_data/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#> New names:\n#> * `` -> `...1`\n\nbikeshops_tbl <- read_excel(path = \"../../ds_data/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n\n# Procedure Plan, data clean up ----\n# Like in the exercise\n# 3. Joining data ----\nleft_join(orderlines_tbl, bikes_tbl, by = c(\"product.id\" = \"bike.id\"))\n\n\n\n  \n\n\nbike_orderlines_joined_2_tbl <- orderlines_tbl %>%\n  left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\nbike_orderlines_joined_2_tbl\n\n\n\n  \n\n\n# 4. Wrangling data ----\nbike_orderlines_wrangled_2_tbl <- bike_orderlines_joined_2_tbl %>%\n  \n  # 4.1 Add the total price (price * quantity)\n  mutate(total.price = price * quantity) %>%\n  \n  # 4.3 Optional: Reorganize. Using select to grab or remove unnecessary columns\n  # 4.3.1 by exact column name\n  select(-...1, -gender, -category, -url, -model, -model.year, -frame.material, -weight, -name, -lat, -lng) %>%\n  \n  # 4.3.2 by a pattern\n  select(-ends_with(\".id\")) %>%\n  \n  # 4.3.3 Actually we need the column \"order.id\". Let's bind it back to the data\n  bind_cols(bike_orderlines_joined_2_tbl %>% select(order.id)) %>%\n  \n  # 4.3.4 Separate the location\n  separate(col = location,\n           into = c(\"city\", \"state\"),\n           sep = \", \",\n           convert = T) %>%\n  \n  # 4.3.4 You can reorder the data by selecting the columns in your desired order.\n  select(order.id, city, state,\n         price, quantity, total.price,\n         everything()) %>%\n  \n  # 4.4 Rename columns because we actually wanted underscores instead of the dots\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n\n# CHALLENGE 1 ----\n\n# Challenge 1.1 Revenue by state ----\n# Step 1 - Manipulate\nsales_by_loc_tbl <- bike_orderlines_wrangled_2_tbl %>%\n  select(state, total_price) %>%\n  group_by(state) %>%\n  summarize(sales = sum(total_price)) %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\",\n                                     decimal.mark = \",\",\n                                     prefix = \"\",\n                                     suffix = \" €\"))\nsales_by_loc_tbl\n\n\n\n  \n\n\n# Step 2 - Visualize\nsales_by_loc_tbl %>%\n  ggplot(aes(x = state, y = sales)) +\n  geom_col(fill = \"#2DC6D6\") +\n  #geom_label(aes(label = sales_text)) +\n  #geom_smooth(method = \"lm\", se = FALSE) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by state\", \n    x = \"\", \n    y = \"Revenue\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#revenue-by-state-and-year",
    "href": "content/01_journal/01_tidyverse.html#revenue-by-state-and-year",
    "title": "Tidyverse",
    "section": "\n7.2 Revenue by state and year",
    "text": "7.2 Revenue by state and year\n\n# Challenge 1.2 Revenue by state and year ----\n# Step 1 - Manipulate\nsales_by_loc_year_tbl <- bike_orderlines_wrangled_2_tbl %>%\n  select(state, total_price, order_date) %>%\n  mutate(year = year(order_date)) %>%\n  group_by(state, year) %>%\n  summarize(sales = sum(total_price)) %>%\n  ungroup() %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\",\n                                     decimal.mark = \",\",\n                                     prefix = \"\",\n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'state'. You can override using the\n#> `.groups` argument.\n\nsales_by_loc_year_tbl\n\n\n\n  \n\n\n# Step 2 - Visualize\nsales_by_loc_year_tbl %>%\n  ggplot(aes(x = year, y = sales, fill = states)) +\n  geom_col(fill = \"#2DC6D6\") +\n  facet_wrap(~ state)+\n  #geom_label(aes(label = sales_text)) +\n  #geom_smooth(method = \"lm\", se = FALSE) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by year and state\",\n    fill = \"State\",\n    y = \"Revenue\",\n    x = \"Year\"\n  )+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#patent-dominance-what-us-company-corporation-has-the-most-patents-list-the-10-us-companies-with-the-most-assignedgranted-patents.",
    "href": "content/01_journal/03_data_wrangling.html#patent-dominance-what-us-company-corporation-has-the-most-patents-list-the-10-us-companies-with-the-most-assignedgranted-patents.",
    "title": "Data Wrangling",
    "section": "\n1.1 Patent Dominance: What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.",
    "text": "1.1 Patent Dominance: What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.\nI think I did okay with the first question, but I did not really use the data.table-package. I guess I forgot to actually turn it into a data.table. And I don’t know if I even used the right columns.\n\n# Data preparation ----\n# Alternative 1:\ncol_types <- list(    # reduced because the link for the original USPTO data was broken\n  id = col_character(),\n  #type = col_character(),\n  #number = col_character(),\n  #country = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  #abstract = col_character(),\n  #title = col_character(),\n  #kind = col_character(),\n  num_claims = col_double()\n  #filename = col_character(),\n  #withdrawn = col_double()\n)\n\npatent_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# assignee_tbl prep\nassignee_col_types <- list(\n  id = col_character(),\n  type = col_character(),\n  organization = col_character()\n)\n\nassignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = assignee_col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# patent_assignee_tbl prep\npatent_assignee_col_types <- list(\n  patent_id = col_character(),\n  assignee_id = col_character()\n)\n\npatent_assignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = patent_assignee_col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# 1. Patent Dominance: What US company / corporation has the most patents? ----\n# List the 10 US companies with the most assigned/granted patents.\n\n# Rename id to assignee_id\nsetnames(assignee_tbl, \"id\", \"assignee_id\")\n\n# Combine Data\ncombined_assignee_tbl <- merge(x = assignee_tbl, y = patent_assignee_tbl,\n                               by = \"assignee_id\",\n                               all.x = TRUE, \n                               all.y = FALSE)\n\nsetnames(patent_tbl, \"id\", \"patent_id\")\n\ncombine_patent_assignee_tbl <-  merge(x = combined_assignee_tbl, y = patent_tbl,\n                                      by = \"patent_id\",\n                                      all.x = TRUE, \n                                      all.y = FALSE)\n\ncombine_patent_assignee_tbl %>%\n  group_by(organization) %>%\n  summarise(granted_patents = sum(num_claims)) %>%\n  ungroup() %>%\n  arrange(desc(granted_patents)) %>%\n  slice(1:10)\n\n\n\n  \n\n\n# I couldn't extract US companies"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#recent-patent-activity-what-us-company-had-the-most-patents-granted-in-august-2014-list-the-top-10-companies-with-the-most-new-granted-patents-for-august-2014.",
    "href": "content/01_journal/03_data_wrangling.html#recent-patent-activity-what-us-company-had-the-most-patents-granted-in-august-2014-list-the-top-10-companies-with-the-most-new-granted-patents-for-august-2014.",
    "title": "Data Wrangling",
    "section": "\n1.2 Recent patent activity: What US company had the most patents granted in August 2014? List the top 10 companies with the most new granted patents for August 2014.",
    "text": "1.2 Recent patent activity: What US company had the most patents granted in August 2014? List the top 10 companies with the most new granted patents for August 2014.\nThis one I could not finish. I did not understand how to set up the command to sort it by the organization, year, and month.\n\n# 2. Recent patent activity: What US company had the most patents granted in August 2014? ----\n# List the top 10 companies with the most new granted patents for August 2014.\n\nsplit_date_patent_tbl <- combine_patent_assignee_tbl %>%\n  mutate(date = as.character(date))%>%\n  separate(col = date,\n           into = c(\"year\", \"month\", \"day\"),\n           sep = \"-\", remove = TRUE) %>%\n  mutate(\n    year = as.numeric(year),\n    month = as.numeric(month),\n    day = as.numeric(day)\n  )\n\nsplit_date_patent_dt <- as.data.table(split_date_patent_tbl)\nclass(split_date_patent_dt)\n\n#> [1] \"data.table\" \"data.frame\"\n\nsplit_date_patent_dt %>%\n  mutate(num_claims = as.numeric(num_claims))\n\n\n\n  \n\n\nsetkey(split_date_patent_dt, \"organization\")\nkey(split_date_patent_dt)\n\n#> [1] \"organization\"\n\nsetorderv(split_date_patent_dt, c(\"organization\", \"year\", \"month\"))\n\n# split_date_patent_dt[, ] # I don't know...\n\n##Innovation in Tech: What is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?\nI did not even start this one."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#patent-dominance",
    "href": "content/01_journal/03_data_wrangling.html#patent-dominance",
    "title": "Data Wrangling",
    "section": "\n1.1 Patent Dominance\n",
    "text": "1.1 Patent Dominance\n\nWhat US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.\nI think I did okay with the first question, but I did not really use the data.table-package. I guess I forgot to actually turn it into a data.table. And I don’t know if I even used the right columns.\n\n# Data preparation ----\n# Alternative 1:\ncol_types <- list(    # reduced because the link for the original USPTO data was broken\n  id = col_character(),\n  #type = col_character(),\n  #number = col_character(),\n  #country = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  #abstract = col_character(),\n  #title = col_character(),\n  #kind = col_character(),\n  num_claims = col_double()\n  #filename = col_character(),\n  #withdrawn = col_double()\n)\n\npatent_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# assignee_tbl prep\nassignee_col_types <- list(\n  id = col_character(),\n  type = col_character(),\n  organization = col_character()\n)\n\nassignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = assignee_col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# patent_assignee_tbl prep\npatent_assignee_col_types <- list(\n  patent_id = col_character(),\n  assignee_id = col_character()\n)\n\npatent_assignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = patent_assignee_col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# 1. Patent Dominance: What US company / corporation has the most patents? ----\n# List the 10 US companies with the most assigned/granted patents.\n\n# Rename id to assignee_id\nsetnames(assignee_tbl, \"id\", \"assignee_id\")\n\n# Combine Data\ncombined_assignee_tbl <- merge(x = assignee_tbl, y = patent_assignee_tbl,\n                               by = \"assignee_id\",\n                               all.x = TRUE, \n                               all.y = FALSE)\n\nsetnames(patent_tbl, \"id\", \"patent_id\")\n\ncombine_patent_assignee_tbl <-  merge(x = combined_assignee_tbl, y = patent_tbl,\n                                      by = \"patent_id\",\n                                      all.x = TRUE, \n                                      all.y = FALSE)\n\ncombine_patent_assignee_tbl %>%\n  group_by(organization) %>%\n  summarise(granted_patents = sum(num_claims)) %>%\n  ungroup() %>%\n  arrange(desc(granted_patents)) %>%\n  slice(1:10)\n\n\n\n  \n\n\n# I couldn't extract US companies"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "href": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "title": "Data Wrangling",
    "section": "\n1.2 Recent patent activity\n",
    "text": "1.2 Recent patent activity\n\nWhat US company had the most patents granted in August 2014? List the top 10 companies with the most new granted patents for August 2014.\nI couldn’t finish this one. I did not understand how to set up the command to sort it by the organization, year, and month.\n\n# 2. Recent patent activity: What US company had the most patents granted in August 2014? ----\n# List the top 10 companies with the most new granted patents for August 2014.\n\nsplit_date_patent_tbl <- combine_patent_assignee_tbl %>%\n  mutate(date = as.character(date))%>%\n  separate(col = date,\n           into = c(\"year\", \"month\", \"day\"),\n           sep = \"-\", remove = TRUE) %>%\n  mutate(\n    year = as.numeric(year),\n    month = as.numeric(month),\n    day = as.numeric(day)\n  )\n\nsplit_date_patent_dt <- as.data.table(split_date_patent_tbl)\nclass(split_date_patent_dt)\n\n#> [1] \"data.table\" \"data.frame\"\n\nsplit_date_patent_dt %>%\n  mutate(num_claims = as.numeric(num_claims)) %>%\n  view()\n\nsetkey(split_date_patent_dt, \"organization\")\nkey(split_date_patent_dt)\n\n#> [1] \"organization\"\n\nsetorderv(split_date_patent_dt, c(\"organization\", \"year\", \"month\"))\n\n# split_date_patent_dt[, ] # I don't know..."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "href": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "title": "Data Wrangling",
    "section": "\n1.3 Innovation in Tech\n",
    "text": "1.3 Innovation in Tech\n\nWhat is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?\nI did not even start this one."
  }
]